{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNoAaNkWATL07F04W+ucF8Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from __future__ import division\n","from torchvision import models\n","from torchvision import transforms\n","from PIL import Image\n","import argparse\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg"],"metadata":{"id":"obtOBTd6kKXa","executionInfo":{"status":"ok","timestamp":1688916786258,"user_tz":-120,"elapsed":7896,"user":{"displayName":"Visiope Project","userId":"04384632279472658731"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4mhdZ6wj9eB","executionInfo":{"status":"ok","timestamp":1688916816307,"user_tz":-120,"elapsed":30056,"user":{"displayName":"Visiope Project","userId":"04384632279472658731"}},"outputId":"40402bb8-b9a1-494e-a032-54b700185b8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/',force_remount=True)"]},{"cell_type":"code","source":["os.chdir('/content/drive/MyDrive/Neural_Style_Transfer/')\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"20RLP4qtkQMw","executionInfo":{"status":"ok","timestamp":1688916816681,"user_tz":-120,"elapsed":378,"user":{"displayName":"Visiope Project","userId":"04384632279472658731"}},"outputId":"d2b43fb8-69be-4369-9bdb-0a0e77b5c845"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["images\t\t\t     output_1500.png  output_3000.png\n","Neural_Style_Transfer.ipynb  output_2000.png  output_500.png\n","output_1000.png\t\t     output_2500.png  results\n"]}]},{"cell_type":"code","source":["# IDENTIFY CORRECT DEVICE\n","if torch.backends.mps.is_available():\n","    dev = \"mps\"\n","elif torch.cuda.is_available():\n","    dev = \"cuda\"\n","else:\n","    dev = \"cpu\"\n","\n","device = torch.device(dev)\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8OmX-AWekhio","executionInfo":{"status":"ok","timestamp":1688916819025,"user_tz":-120,"elapsed":217,"user":{"displayName":"Visiope Project","userId":"04384632279472658731"}},"outputId":"d5f0532c-1c1e-4ad7-9b3b-3c9c3d5e11d1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"markdown","source":["PREPROCESSING"],"metadata":{"id":"B3KtlhKZlZxT"}},{"cell_type":"code","source":["def load_picture(picture_path, transform=None, max_size=None, shape=None):\n","   # image --> pytorch tensor\n","    pic = Image.open(picture_path)\n","\n","    if max_size:\n","        scale = max_size / max(pic.size)\n","        size = np.array(pic.size) * scale\n","        pic = pic.resize(size.astype(int), Image.ANTIALIAS)\n","\n","    if shape:\n","        pic = pic.resize(shape, Image.LANCZOS)\n","\n","    if transform:\n","        pic = transform(pic).unsqueeze(0)\n","\n","    return pic.to(device)"],"metadata":{"id":"CBzd2VbGkZDc","executionInfo":{"status":"ok","timestamp":1688916821471,"user_tz":-120,"elapsed":247,"user":{"displayName":"Visiope Project","userId":"04384632279472658731"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=(0.485, 0.456, 0.406),\n","        std=(0.229, 0.224, 0.225)),\n","])"],"metadata":{"id":"ePAfpeVGk0CV","executionInfo":{"status":"ok","timestamp":1688916823422,"user_tz":-120,"elapsed":405,"user":{"displayName":"Visiope Project","userId":"04384632279472658731"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["FEATURE EXTRACTOR"],"metadata":{"id":"3Pir8IPjliZ0"}},{"cell_type":"code","source":["class VGGNet(nn.Module):\n","    def __init__(self):\n","        super(VGGNet, self).__init__()\n","        self.vgg = models.vgg19(pretrained=True).features\n","\n","    def forward(self, x):\n","        # Specify layer indices for feature extraction\n","        layer_indices = [0, 5, 10, 19, 28]\n","        features = []\n","\n","        for idx, (name, layer) in enumerate(self.vgg._modules.items()):\n","            x = layer(x)\n","            if idx in layer_indices:\n","                features.append(x)\n","\n","        return features\n",""],"metadata":{"id":"uNt7CkPFkmz5","executionInfo":{"status":"ok","timestamp":1688916824594,"user_tz":-120,"elapsed":203,"user":{"displayName":"Visiope Project","userId":"04384632279472658731"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["CONFIGURATION"],"metadata":{"id":"v8f4opu9l52V"}},{"cell_type":"code","source":["base = load_picture(\"./images/greatwave.jpg\", transform=transform)\n","painting = load_picture(\n","    \"./images/picasso.jpg\",\n","    transform=transform,\n","    shape=[base.size(2), base.size(3)],\n",")\n","\n","goal_image_path = \"./output.png\"\n","\n","if os.path.isfile(goal_image_path):\n","    goal = load_picture(\n","        goal_image_path, transform=transform\n","    ).requires_grad_(True)\n","else:\n","    goal = base.clone().requires_grad_(True)"],"metadata":{"id":"xwyxjVaskznn","executionInfo":{"status":"ok","timestamp":1688916831514,"user_tz":-120,"elapsed":2975,"user":{"displayName":"Visiope Project","userId":"04384632279472658731"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["lr = 0.003 # default\n","painting_weight = 100 # default 120\n","total_steps = 3000 #default 100\n","print_step = 50 # default total_steps // 10\n","save_step = 500 # default total_steps // 5\n","max_size = 400\n","\n","optimizer = torch.optim.Adam([goal], lr=lr, betas=[0.5, 0.999])\n","net = VGGNet().to(device).eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IjFfMxkumDzy","executionInfo":{"status":"ok","timestamp":1688916844066,"user_tz":-120,"elapsed":9643,"user":{"displayName":"Visiope Project","userId":"04384632279472658731"}},"outputId":"8887743b-d89f-48fa-f1c5-8a0b55373458"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n","100%|██████████| 548M/548M [00:06<00:00, 82.3MB/s]\n"]}]},{"cell_type":"markdown","source":["RUN"],"metadata":{"id":"G0e4ro3Wk4JH"}},{"cell_type":"code","source":["for step in range(total_steps):\n","    goal_features = net(goal)\n","    base_features = net(base)\n","    painting_features = net(painting)\n","\n","    painting_loss = 0\n","    base_loss = 0\n","\n","    for goal_f, base_f, painting_f in zip(\n","        goal_features, base_features, painting_features\n","    ):\n","        base_loss += torch.mean((goal_f - content_f) ** 2)\n","\n","        _, c, h, w = content_f.size()\n","        goal_f = goal_f.reshape(c, -1)\n","        painting_f = painting_f.reshape(c, -1)\n","\n","        goal_gram = torch.mm(goal_f, goal_f.t())\n","        painting_gram = torch.mm(painting_f, painting_f.t())\n","\n","        painting_loss += torch.mean((goal_gram - painting_gram) ** 2) / (c * h * w)\n","\n","    loss = base_loss + painting_weight * painting_loss\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","\n","\n","    if (step+1) % print_step == 0:\n","            print ('Step [{}/{}], Base Loss: {:.4f}, Painting Loss: {:.4f}' .format(step+1, total_steps, base_loss.item(), painting_loss.item()))\n","\n","    if (step+1) % save_step == 0:\n","            # Save the generated image\n","            denorm = transforms.Normalize((-2.12, -2.04, -1.80), (4.37, 4.46, 4.44))\n","            pic = goal.clone().squeeze()\n","            pic = denorm(img).clamp_(0, 1)\n","            save_folder = f\"./output_{step + 1}.png\"\n","\n","            torchvision.utils.save_image(pic, save_folder)\n","\n"],"metadata":{"id":"fMjZKDi1le_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pic_orig = mpimg.imread('./images/colosseo.jpg')\n","\n","# Display the image using Matplotlib\n","plt.imshow(pic_orig)\n","plt.show()"],"metadata":{"id":"O0Iw5w-ohPEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pic1 = mpimg.imread('output_500.png')\n","pic2 = mpimg.imread('output_1000.png')\n","pic3 = mpimg.imread('output_1500.png')\n","pic4 = mpimg.imread('output_2000.png')\n","pic5 = mpimg.imread('output_2500.png')\n","pic6 = mpimg.imread('output_3000.png')\n","\n","\n","# Load the images\n","img1 = np.array(pic1)\n","img2 = np.array(pic2)\n","img3 = np.array(pic3)\n","img4 = np.array(pic4)\n","img5 = np.array(pic5)\n","img6 = np.array(pic6)\n","\n","# Create a 2 x 3 grid of subplots\n","fig, ax = plt.subplots(2, 3, figsize=(10, 6), gridspec_kw={'height_ratios': [2, 1]})\n","\n","# Plot the images in the grid\n","ax[0, 0].imshow(img1)\n","ax[0, 0].set_title('After 500 steps')\n","ax[0, 1].imshow(img2)\n","ax[0, 1].set_title('After 1000 steps')\n","ax[0, 2].imshow(img3)\n","ax[0, 2].set_title('After 1500 steps')\n","ax[1, 0].imshow(img4)\n","ax[1, 0].set_title('After 2000 steps')\n","ax[1, 1].imshow(img5)\n","ax[1, 1].set_title('After 2500 steps')\n","ax[1, 2].imshow(img6)\n","ax[1, 2].set_title('After 3000 steps')\n","\n","# Hide the axes for a cleaner layout\n","for i in range(2):\n","    for j in range(3):\n","        ax[i, j].axis('off')\n","\n","plt.tight_layout()\n","\n","# Save the plot to a PNG file\n","plt.savefig('./results/greatwave-picasso.png')\n","\n","plt.show()"],"metadata":{"id":"B5SMbZYV36zT"},"execution_count":null,"outputs":[]}]}